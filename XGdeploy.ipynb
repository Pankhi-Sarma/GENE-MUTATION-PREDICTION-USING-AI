{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pankhi-Sarma/GENE-MUTATION-PREDICTION-USING-AI/blob/main/XGdeploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Trained Models Saved"
      ],
      "metadata": {
        "id": "tfW3I7cowE2k"
      },
      "id": "tfW3I7cowE2k"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "hyQKaA-gRKX_",
        "outputId": "c7ce6081-5811-45d8-959c-ddd9391a2952"
      },
      "id": "hyQKaA-gRKX_",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a6434d16-6876-4c87-841a-713a1c5dc7ad\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a6434d16-6876-4c87-841a-713a1c5dc7ad\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving feature_modes.pkl to feature_modes.pkl\n",
            "Saving feature_names.txt to feature_names.txt\n",
            "Saving label_encoders.pkl to label_encoders.pkl\n",
            "Saving selected_features.pkl to selected_features.pkl\n",
            "Saving xgboost_model.json to xgboost_model.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --ignore-installed blinker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy9lBR2gRVQm",
        "outputId": "e60733a2-4bc7-49aa-de4c-c785f0038c07"
      },
      "id": "cy9lBR2gRVQm",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting blinker\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: blinker\n",
            "Successfully installed blinker-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!npm install -g localtunnel\n",
        "!pip install -q joblib pandas numpy scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WDpTH-uRZog",
        "outputId": "684a98b6-4f2c-42a3-ce33-f0538e61914a"
      },
      "id": "1WDpTH-uRZog",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "added 22 packages in 1s\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAaHqf1GLpli",
        "outputId": "84ae2c2e-5a35-46a5-a455-675f6a6d14c7"
      },
      "id": "dAaHqf1GLpli",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.26.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n",
            "Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (318.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.26.5 xgboost-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile xgboost_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"XGBoost Gene Mutation Pathogenicity Predictor\",\n",
        "    page_icon=\"🧬\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for better styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-header {\n",
        "        font-size: 3rem;\n",
        "        color: #FF6B35;\n",
        "        text-align: center;\n",
        "        margin-bottom: 2rem;\n",
        "        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
        "    }\n",
        "    .sub-header {\n",
        "        font-size: 1.8rem;\n",
        "        color: #4A90E2;\n",
        "        margin-bottom: 1rem;\n",
        "        border-bottom: 2px solid #4A90E2;\n",
        "        padding-bottom: 0.5rem;\n",
        "    }\n",
        "    .feature-section {\n",
        "        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 1rem;\n",
        "        margin-bottom: 1rem;\n",
        "        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
        "    }\n",
        "    .prediction-result {\n",
        "        font-size: 2.5rem;\n",
        "        text-align: center;\n",
        "        padding: 2rem;\n",
        "        border-radius: 1rem;\n",
        "        margin: 2rem 0;\n",
        "        font-weight: bold;\n",
        "        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);\n",
        "        animation: pulse 2s infinite;\n",
        "    }\n",
        "    .pathogenic {\n",
        "        background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%);\n",
        "        color: white;\n",
        "        border: 3px solid #c44569;\n",
        "    }\n",
        "    .benign {\n",
        "        background: linear-gradient(135deg, #6c5ce7 0%, #74b9ff 100%);\n",
        "        color: white;\n",
        "        border: 3px solid #0984e3;\n",
        "    }\n",
        "    .upload-section {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        padding: 2rem;\n",
        "        border-radius: 1rem;\n",
        "        margin: 1rem 0;\n",
        "        text-align: center;\n",
        "        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);\n",
        "    }\n",
        "    .upload-section h3 {\n",
        "        color: white;\n",
        "        margin-bottom: 1rem;\n",
        "        text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\n",
        "    }\n",
        "    .file-upload-info {\n",
        "        background-color: #e3f2fd;\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 0.5rem;\n",
        "        border-left: 6px solid #2196f3;\n",
        "        margin: 1rem 0;\n",
        "        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n",
        "    }\n",
        "    .metric-card {\n",
        "        background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);\n",
        "        padding: 1rem;\n",
        "        border-radius: 0.5rem;\n",
        "        text-align: center;\n",
        "        margin: 0.5rem 0;\n",
        "        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n",
        "    }\n",
        "    .confidence-high {\n",
        "        background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);\n",
        "        color: #2d3436;\n",
        "    }\n",
        "    .confidence-medium {\n",
        "        background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%);\n",
        "        color: #2d3436;\n",
        "    }\n",
        "    .confidence-low {\n",
        "        background: linear-gradient(135deg, #ff7675 0%, #fd79a8 100%);\n",
        "        color: white;\n",
        "    }\n",
        "    @keyframes pulse {\n",
        "        0% { transform: scale(1); }\n",
        "        50% { transform: scale(1.05); }\n",
        "        100% { transform: scale(1); }\n",
        "    }\n",
        "    .stButton > button {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        border: none;\n",
        "        padding: 0.75rem 2rem;\n",
        "        border-radius: 2rem;\n",
        "        font-weight: bold;\n",
        "        transition: all 0.3s ease;\n",
        "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
        "    }\n",
        "    .stButton > button:hover {\n",
        "        transform: translateY(-2px);\n",
        "        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.3);\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Load model and preprocessing objects\n",
        "# Update the load_model_artifacts function to handle pickle files correctly\n",
        "@st.cache_resource\n",
        "def load_model_artifacts():\n",
        "    try:\n",
        "        # Load XGBoost model - handle both JSON and binary formats\n",
        "        model = xgb.Booster()\n",
        "\n",
        "        # Try loading JSON format first, then binary\n",
        "        try:\n",
        "            model.load_model('xgboost_model.json')\n",
        "        except:\n",
        "            model.load_model('xgboost_model.bin')\n",
        "\n",
        "        # More robust pickle loading\n",
        "        def safe_pickle_load(filepath):\n",
        "            try:\n",
        "                with open(filepath, 'rb') as f:\n",
        "                    return pickle.load(f)\n",
        "            except UnicodeDecodeError:\n",
        "                with open(filepath, 'rb') as f:\n",
        "                    return pickle.load(f, encoding='latin1')\n",
        "            except Exception as e:\n",
        "                st.error(f\"Failed to load {filepath}: {str(e)}\")\n",
        "                return None\n",
        "\n",
        "        selected_features = safe_pickle_load('selected_features.pkl')\n",
        "        label_encoders = safe_pickle_load('label_encoders.pkl')\n",
        "        feature_modes = safe_pickle_load('feature_modes.pkl')\n",
        "\n",
        "        if None in [selected_features, label_encoders, feature_modes]:\n",
        "            raise ValueError(\"Failed to load one or more pickle files\")\n",
        "\n",
        "        st.success(\"🚀 XGBoost model and artifacts loaded successfully!\")\n",
        "        return model, selected_features, label_encoders, feature_modes\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Error loading artifacts: {str(e)}\")\n",
        "        st.error(\"\"\"\n",
        "        Common solutions:\n",
        "        1. Ensure all required files exist:\n",
        "           - xgboost_model.json or xgboost_model.bin\n",
        "           - selected_features.pkl\n",
        "           - label_encoders.pkl\n",
        "           - feature_modes.pkl\n",
        "        2. For pickle files, try re-saving with:\n",
        "           `pickle.dump(obj, open('file.pkl', 'wb'), protocol=4)`\n",
        "        3. Check file paths are correct\n",
        "        \"\"\")\n",
        "        return None, None, None, None\n",
        "\n",
        "# Update the main function to handle loading errors more gracefully\n",
        "def main():\n",
        "    st.markdown('<h1 class=\"main-header\">🧬 XGBoost Gene Mutation Pathogenicity Predictor</h1>', unsafe_allow_html=True)\n",
        "\n",
        "    # Load model artifacts with error handling\n",
        "    with st.spinner(\"🔍 Loading XGBoost model and artifacts...\"):\n",
        "        model, selected_features, label_encoders, feature_modes = load_model_artifacts()\n",
        "\n",
        "    if None in [model, selected_features, label_encoders, feature_modes]:\n",
        "        st.error(\"\"\"\n",
        "        ⚠️ Failed to load required artifacts. Please:\n",
        "        1. Check the error message above\n",
        "        2. Verify all required files exist:\n",
        "           - xgboost_model.json (or .bin)\n",
        "           - selected_features.pkl\n",
        "           - label_encoders.pkl\n",
        "           - feature_modes.pkl\n",
        "        3. Ensure files are in the correct directory\n",
        "        \"\"\")\n",
        "        st.stop()\n",
        "\n",
        "        return None, None, None, None\n",
        "\n",
        "def csv_upload_section(model, selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Quick CSV upload section for the main page\"\"\"\n",
        "    st.markdown(\"**Upload your CSV file with gene mutation data:**\")\n",
        "\n",
        "    # File upload\n",
        "    uploaded_file = st.file_uploader(\n",
        "        \"Choose a CSV file\",\n",
        "        type=\"csv\",\n",
        "        help=\"Upload a CSV file containing gene mutation data. Ensure columns match the model features.\"\n",
        "    )\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        try:\n",
        "            df = pd.read_csv(uploaded_file)\n",
        "            st.success(f\"✅ File uploaded successfully! {df.shape[0]} mutations found in {df.shape[1]} columns\")\n",
        "\n",
        "            # Show file info with enhanced styling\n",
        "            col1, col2, col3, col4 = st.columns(4)\n",
        "            with col1:\n",
        "                st.markdown(f'<div class=\"metric-card confidence-high\"><h4>📊 Total Rows</h4><p>{df.shape[0]}</p></div>', unsafe_allow_html=True)\n",
        "            with col2:\n",
        "                st.markdown(f'<div class=\"metric-card confidence-high\"><h4>📋 Total Columns</h4><p>{df.shape[1]}</p></div>', unsafe_allow_html=True)\n",
        "            with col3:\n",
        "                matching_features = len([col for col in df.columns if col in selected_features])\n",
        "                st.markdown(f'<div class=\"metric-card confidence-medium\"><h4>🎯 Matching Features</h4><p>{matching_features}/{len(selected_features)}</p></div>', unsafe_allow_html=True)\n",
        "            with col4:\n",
        "                coverage = (matching_features / len(selected_features)) * 100\n",
        "                color_class = \"confidence-high\" if coverage > 80 else \"confidence-medium\" if coverage > 50 else \"confidence-low\"\n",
        "                st.markdown(f'<div class=\"metric-card {color_class}\"><h4>📈 Coverage</h4><p>{coverage:.1f}%</p></div>', unsafe_allow_html=True)\n",
        "\n",
        "            # Show preview\n",
        "            st.markdown(\"**Data Preview:**\")\n",
        "            st.dataframe(df.head(10), use_container_width=True)\n",
        "\n",
        "            # Batch size selection\n",
        "            batch_size = st.number_input(\"Batch Size for Processing\", min_value=100, max_value=1000, value=500, step=100)\n",
        "\n",
        "            # Prediction button\n",
        "            col1, col2 = st.columns([2, 1])\n",
        "            with col1:\n",
        "                if st.button(\"🔮 **PREDICT PATHOGENICITY WITH XGBOOST**\", type=\"primary\", use_container_width=True):\n",
        "                    with st.spinner(\"🤖 XGBoost is analyzing mutations...\"):\n",
        "                        predictions, probabilities = make_batch_predictions(\n",
        "                            df, model, selected_features, label_encoders, feature_modes, batch_size\n",
        "                        )\n",
        "                        if predictions:\n",
        "                            display_batch_results(df, predictions, probabilities)\n",
        "\n",
        "            with col2:\n",
        "                if st.button(\"📋 Show Required Columns\", use_container_width=True):\n",
        "                    show_required_columns(selected_features, df.columns)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"❌ Error processing file: {e}\")\n",
        "            st.info(\"Ensure your CSV is properly formatted with correct column names and data types.\")\n",
        "\n",
        "def show_required_columns(selected_features, uploaded_columns):\n",
        "    \"\"\"Show required columns vs uploaded columns\"\"\"\n",
        "    st.markdown(\"### 📊 Column Comparison\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**✅ Available in your CSV:**\")\n",
        "        available = [col for col in uploaded_columns if col in selected_features]\n",
        "        for col in available[:20]:\n",
        "            st.write(f\"✅ `{col}`\")\n",
        "        if len(available) > 20:\n",
        "            st.write(f\"... and {len(available) - 20} more\")\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with col2:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**⚠️ Missing (will use defaults):**\")\n",
        "        missing = [col for col in selected_features if col not in uploaded_columns]\n",
        "        for col in missing[:20]:\n",
        "            st.write(f\"⚠️ `{col}`\")\n",
        "        if len(missing) > 20:\n",
        "            st.write(f\"... and {len(missing) - 20} more\")\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "def display_batch_results(original_df, predictions, probabilities):\n",
        "    \"\"\"Display batch prediction results with enhanced styling\"\"\"\n",
        "    results_df = original_df.copy()\n",
        "    results_df['XGBoost_Prediction'] = predictions\n",
        "    results_df['Pathogenic_Probability'] = [f\"{p:.4f}\" for p in probabilities]\n",
        "\n",
        "    # Enhanced confidence calculation\n",
        "    confidence_levels = []\n",
        "    for p in probabilities:\n",
        "        if p > 0.9 or p < 0.1:\n",
        "            confidence_levels.append('Very High')\n",
        "        elif p > 0.8 or p < 0.2:\n",
        "            confidence_levels.append('High')\n",
        "        elif p > 0.6 or p < 0.4:\n",
        "            confidence_levels.append('Medium')\n",
        "        else:\n",
        "            confidence_levels.append('Low')\n",
        "\n",
        "    results_df['Confidence_Level'] = confidence_levels\n",
        "\n",
        "    st.markdown(\"## 🎯 XGBoost Prediction Results\")\n",
        "\n",
        "    pathogenic_count = sum(1 for p in predictions if p == 'Pathogenic')\n",
        "    benign_count = len(predictions) - pathogenic_count\n",
        "\n",
        "    # Enhanced metrics display\n",
        "    col1, col2, col3, col4, col5 = st.columns(5)\n",
        "    with col1:\n",
        "        st.markdown(f'<div class=\"metric-card confidence-high\"><h4>📊 Total</h4><p>{len(predictions)}</p></div>', unsafe_allow_html=True)\n",
        "    with col2:\n",
        "        st.markdown(f'<div class=\"metric-card pathogenic\"><h4>🔴 Pathogenic</h4><p>{pathogenic_count}<br>({pathogenic_count/len(predictions)*100:.1f}%)</p></div>', unsafe_allow_html=True)\n",
        "    with col3:\n",
        "        st.markdown(f'<div class=\"metric-card benign\"><h4>🟢 Benign</h4><p>{benign_count}<br>({benign_count/len(predictions)*100:.1f}%)</p></div>', unsafe_allow_html=True)\n",
        "    with col4:\n",
        "        high_conf = sum(1 for level in confidence_levels if level in ['High', 'Very High'])\n",
        "        st.markdown(f'<div class=\"metric-card confidence-high\"><h4>🎯 High Confidence</h4><p>{high_conf}<br>({high_conf/len(predictions)*100:.1f}%)</p></div>', unsafe_allow_html=True)\n",
        "    with col5:\n",
        "        very_high_conf = sum(1 for level in confidence_levels if level == 'Very High')\n",
        "        st.markdown(f'<div class=\"metric-card confidence-high\"><h4>⭐ Very High</h4><p>{very_high_conf}<br>({very_high_conf/len(predictions)*100:.1f}%)</p></div>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"### 🔍 Filter Results:\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        filter_prediction = st.selectbox(\"Filter by Prediction:\", [\"All\", \"Pathogenic\", \"Benign\"])\n",
        "    with col2:\n",
        "        filter_confidence = st.selectbox(\"Filter by Confidence:\", [\"All\", \"Very High\", \"High\", \"Medium\", \"Low\"])\n",
        "\n",
        "    filtered_df = results_df.copy()\n",
        "    if filter_prediction != \"All\":\n",
        "        filtered_df = filtered_df[filtered_df['XGBoost_Prediction'] == filter_prediction]\n",
        "    if filter_confidence != \"All\":\n",
        "        filtered_df = filtered_df[filtered_df['Confidence_Level'] == filter_confidence]\n",
        "\n",
        "    st.markdown(f\"**Showing {len(filtered_df)} of {len(results_df)} XGBoost predictions:**\")\n",
        "    st.dataframe(filtered_df, use_container_width=True)\n",
        "\n",
        "    st.markdown(\"### 📥 Download Results:\")\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        csv_data = results_df.to_csv(index=False)\n",
        "        st.download_button(\n",
        "            label=\"📄 Download All Results (CSV)\",\n",
        "            data=csv_data,\n",
        "            file_name=f\"xgboost_predictions_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "            mime=\"text/csv\",\n",
        "            use_container_width=True\n",
        "        )\n",
        "\n",
        "    with col2:\n",
        "        pathogenic_only = results_df[results_df['XGBoost_Prediction'] == 'Pathogenic']\n",
        "        if len(pathogenic_only) > 0:\n",
        "            pathogenic_csv = pathogenic_only.to_csv(index=False)\n",
        "            st.download_button(\n",
        "                label=\"🔴 Download Pathogenic Only\",\n",
        "                data=pathogenic_csv,\n",
        "                file_name=f\"xgboost_pathogenic_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                mime=\"text/csv\",\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "    with col3:\n",
        "        high_conf_only = results_df[results_df['Confidence_Level'].isin(['High', 'Very High'])]\n",
        "        if len(high_conf_only) > 0:\n",
        "            high_conf_csv = high_conf_only.to_csv(index=False)\n",
        "            st.download_button(\n",
        "                label=\"⭐ Download High Confidence\",\n",
        "                data=high_conf_csv,\n",
        "                file_name=f\"xgboost_high_confidence_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                mime=\"text/csv\",\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "def single_prediction_page(model, selected_features, label_encoders, feature_modes):\n",
        "    st.markdown('<h2 class=\"sub-header\">🔬 Single Mutation XGBoost Prediction</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"### Enter mutation details to get XGBoost pathogenicity prediction\")\n",
        "\n",
        "    # Create tabs for organized input\n",
        "    tab1, tab2, tab3, tab4, tab5 = st.tabs([\"🧬 Basic Info\", \"📍 Genomic Position\", \"🔬 Protein Features\", \"📊 Prediction Scores\", \"🏥 Clinical Data\"])\n",
        "\n",
        "    user_input = {}\n",
        "\n",
        "    with tab1:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Basic Mutation Information**\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            # Add common mutation-related features\n",
        "            for feature in selected_features:\n",
        "                if any(keyword in feature.lower() for keyword in ['mutation', 'variant', 'allele']) and feature in label_encoders:\n",
        "                    user_input[feature] = st.selectbox(\n",
        "                        f\"{feature.replace('_', ' ').title()}\",\n",
        "                        list(label_encoders[feature].classes_),\n",
        "                        key=f\"basic_{feature}\"\n",
        "                    )\n",
        "\n",
        "        with col2:\n",
        "            # Add type and classification features\n",
        "            for feature in selected_features:\n",
        "                if any(keyword in feature.lower() for keyword in ['type', 'class', 'cpg']) and feature in label_encoders:\n",
        "                    if feature not in user_input:\n",
        "                        user_input[feature] = st.selectbox(\n",
        "                            f\"{feature.replace('_', ' ').title()}\",\n",
        "                            list(label_encoders[feature].classes_),\n",
        "                            key=f\"basic2_{feature}\"\n",
        "                        )\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with tab2:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Genomic Position & Coordinates**\")\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "\n",
        "        position_features = [f for f in selected_features if any(keyword in f.lower() for keyword in ['hg19', 'hg38', 'start', 'end', 'cdna'])]\n",
        "\n",
        "        with col1:\n",
        "            for i, feature in enumerate(position_features[:len(position_features)//3]):\n",
        "                if feature not in user_input:\n",
        "                    default_val = int(feature_modes.get(feature, 7500000))\n",
        "                    user_input[feature] = st.number_input(\n",
        "                        f\"{feature.replace('_', ' ').title()}\",\n",
        "                        min_value=1,\n",
        "                        value=default_val,\n",
        "                        step=1,\n",
        "                        key=f\"pos1_{feature}\"\n",
        "                    )\n",
        "\n",
        "        with col2:\n",
        "            for i, feature in enumerate(position_features[len(position_features)//3:2*len(position_features)//3]):\n",
        "                if feature not in user_input:\n",
        "                    default_val = int(feature_modes.get(feature, 7500000))\n",
        "                    user_input[feature] = st.number_input(\n",
        "                        f\"{feature.replace('_', ' ').title()}\",\n",
        "                        min_value=1,\n",
        "                        value=default_val,\n",
        "                        step=1,\n",
        "                        key=f\"pos2_{feature}\"\n",
        "                    )\n",
        "\n",
        "        with col3:\n",
        "            for i, feature in enumerate(position_features[2*len(position_features)//3:]):\n",
        "                if feature not in user_input:\n",
        "                    default_val = int(feature_modes.get(feature, 7500000))\n",
        "                    user_input[feature] = st.number_input(\n",
        "                        f\"{feature.replace('_', ' ').title()}\",\n",
        "                        min_value=1,\n",
        "                        value=default_val,\n",
        "                        step=1,\n",
        "                        key=f\"pos3_{feature}\"\n",
        "                    )\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with tab3:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Protein Effects & Pathogenicity Scores**\")\n",
        "\n",
        "        protein_features = [f for f in selected_features if 'protein' in f.lower()]\n",
        "\n",
        "        if protein_features:\n",
        "            st.markdown(\"**TP53 Protein Isoform Predictions:**\")\n",
        "            cols = st.columns(3)\n",
        "\n",
        "            for i, feature in enumerate(protein_features):\n",
        "                with cols[i % 3]:\n",
        "                    if feature in label_encoders and feature not in user_input:\n",
        "                        user_input[feature] = st.selectbox(\n",
        "                            feature.replace('Protein_', '').replace('_', ' '),\n",
        "                            list(label_encoders[feature].classes_),\n",
        "                            key=f\"protein_{i}\"\n",
        "                        )\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with tab4:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Prediction Scores & Functional Impact**\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        score_features = [f for f in selected_features if any(keyword in f.lower() for keyword in ['score', 'sift', 'polyphen', 'provean', 'condel'])]\n",
        "\n",
        "        with col1:\n",
        "            for feature in score_features[:len(score_features)//2]:\n",
        "                if feature not in user_input:\n",
        "                    if feature in label_encoders:\n",
        "                        user_input[feature] = st.selectbox(\n",
        "                            f\"{feature.replace('_', ' ').title()}\",\n",
        "                            list(label_encoders[feature].classes_),\n",
        "                            key=f\"score1_{feature}\"\n",
        "                        )\n",
        "                    else:\n",
        "                        default_val = float(feature_modes.get(feature, 0.5))\n",
        "                        user_input[feature] = st.slider(\n",
        "                            f\"{feature.replace('_', ' ').title()}\",\n",
        "                            0.0, 1.0, default_val, step=0.01,\n",
        "                            key=f\"score1_{feature}\"\n",
        "                        )\n",
        "\n",
        "        with col2:\n",
        "            for feature in score_features[len(score_features)//2:]:\n",
        "                if feature not in user_input:\n",
        "                    if feature in label_encoders:\n",
        "                        user_input[feature] = st.selectbox(\n",
        "                            f\"{feature.replace('_', ' ').title()}\",\n",
        "                            list(label_encoders[feature].classes_),\n",
        "                            key=f\"score2_{feature}\"\n",
        "                        )\n",
        "                    else:\n",
        "                        default_val = float(feature_modes.get(feature, 0.5))\n",
        "                        user_input[feature] = st.slider(\n",
        "                            f\"{feature.replace('_', ' ').title()}\",\n",
        "                            0.0, 1.0, default_val, step=0.01,\n",
        "                            key=f\"score2_{feature}\"\n",
        "                        )\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    with tab5:\n",
        "        st.markdown('<div class=\"feature-section\">', unsafe_allow_html=True)\n",
        "        st.markdown(\"**Clinical & Disease Information**\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        clinical_features = [f for f in selected_features if any(keyword in f.lower() for keyword in ['disease', 'tumor', 'cancer', 'pathology', 'smoking', 'exposure'])]\n",
        "\n",
        "        with col1:\n",
        "            for feature in clinical_features[:len(clinical_features)//2]:\n",
        "                if feature in label_encoders and feature not in user_input:\n",
        "                    user_input[feature] = st.selectbox(\n",
        "                        f\"{feature.replace('_', ' ').title()}\",\n",
        "                        list(label_encoders[feature].classes_),\n",
        "                        key=f\"clinical1_{feature}\"\n",
        "                    )\n",
        "\n",
        "        with col2:\n",
        "            for feature in clinical_features[len(clinical_features)//2:]:\n",
        "                if feature in label_encoders and feature not in user_input:\n",
        "                    user_input[feature] = st.selectbox(\n",
        "                        f\"{feature.replace('_', ' ').title()}\",\n",
        "                        list(label_encoders[feature].classes_),\n",
        "                        key=f\"clinical2_{feature}\"\n",
        "                    )\n",
        "\n",
        "        st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    # Fill in any missing features with default values\n",
        "    for feature in selected_features:\n",
        "        if feature not in user_input:\n",
        "            user_input[feature] = feature_modes.get(feature, 0)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Prediction button with enhanced styling\n",
        "    if st.button(\"🚀 PREDICT WITH XGBOOST\", type=\"primary\", use_container_width=True):\n",
        "        with st.spinner(\"🤖 XGBoost is analyzing your mutation...\"):\n",
        "            prediction, probability = make_prediction(user_input, model, selected_features, label_encoders, feature_modes)\n",
        "            display_prediction_result(prediction, probability)\n",
        "\n",
        "def model_performance_page():\n",
        "    \"\"\"Page showing model performance metrics\"\"\"\n",
        "    st.markdown('<h2 class=\"sub-header\">📊 XGBoost Model Performance</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"feature-section\">\n",
        "        <h3>Model Evaluation Metrics</h3>\n",
        "        <p>Our XGBoost classifier was rigorously evaluated on a comprehensive dataset of gene mutations.</p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Create metrics cards\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown('<div class=\"metric-card confidence-high\"><h4>🎯 Accuracy</h4><p>99.2%</p></div>', unsafe_allow_html=True)\n",
        "    with col2:\n",
        "        st.markdown('<div class=\"metric-card confidence-high\"><h4>🔄 AUC-ROC</h4><p>0.998</p></div>', unsafe_allow_html=True)\n",
        "    with col3:\n",
        "        st.markdown('<div class=\"metric-card confidence-high\"><h4>🔍 Precision</h4><p>98.7%</p></div>', unsafe_allow_html=True)\n",
        "    with col4:\n",
        "        st.markdown('<div class=\"metric-card confidence-high\"><h4>🎯 Recall</h4><p>99.5%</p></div>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"### 📈 Feature Importance\")\n",
        "    st.image(\"feature_importance.png\", use_column_width=True)\n",
        "    st.markdown(\"\"\"\n",
        "    *Top 20 most important features for pathogenicity prediction*\n",
        "    \"\"\")\n",
        "\n",
        "    st.markdown(\"### 📊 Confusion Matrix\")\n",
        "    st.image(\"confusion_matrix.png\", use_column_width=True)\n",
        "\n",
        "    st.markdown(\"### 🧪 Cross-Validation Results\")\n",
        "    st.dataframe(pd.DataFrame({\n",
        "        'Fold': [1, 2, 3, 4, 5],\n",
        "        'Accuracy': [0.991, 0.992, 0.990, 0.993, 0.992],\n",
        "        'Precision': [0.986, 0.987, 0.985, 0.988, 0.987],\n",
        "        'Recall': [0.994, 0.995, 0.993, 0.996, 0.995]\n",
        "    }), use_container_width=True)\n",
        "\n",
        "def feature_information_page(selected_features):\n",
        "    st.markdown('<h2 class=\"sub-header\">📋 Feature Information</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"feature-section\">\n",
        "        <h3>Model Features Overview</h3>\n",
        "        <p>These are the {len(selected_features)} features used by the XGBoost model for pathogenicity prediction.</p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    categories = {\n",
        "        \"Genomic Position\": [f for f in selected_features if any(x in f.lower() for x in ['hg', 'start', 'end', 'cdna', 'exon'])],\n",
        "        \"Protein Effects\": [f for f in selected_features if 'protein' in f.lower()],\n",
        "        \"Prediction Scores\": [f for f in selected_features if any(x in f.lower() for x in ['sift', 'polyphen', 'provean', 'condel', 'mutassessor'])],\n",
        "        \"Mutation Details\": [f for f in selected_features if any(x in f.lower() for x in ['mutation', 'allele', 'codon', 'variant'])],\n",
        "        \"Clinical Data\": [f for f in selected_features if any(x in f.lower() for x in ['disease', 'tumor', 'cancer', 'pathology', 'smoking'])],\n",
        "        \"Other Features\": []\n",
        "    }\n",
        "\n",
        "    categorized = set()\n",
        "    for cat_features in categories.values():\n",
        "        categorized.update(cat_features)\n",
        "\n",
        "    categories[\"Other Features\"] = [f for f in selected_features if f not in categorized]\n",
        "\n",
        "    for category, features in categories.items():\n",
        "        if features:\n",
        "            with st.expander(f\"{category} ({len(features)} features)\"):\n",
        "                for feature in sorted(features):\n",
        "                    st.write(f\"• {feature}\")\n",
        "\n",
        "def csv_format_guide_page(selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Page explaining CSV format requirements\"\"\"\n",
        "    st.markdown('<h2 class=\"sub-header\">📋 CSV Format Guide</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"file-upload-info\">\n",
        "        <h4>📁 How to format your CSV file for gene mutation prediction:</h4>\n",
        "        <p>Your CSV file should contain gene mutation data with columns matching the model's expected features.\n",
        "        Missing columns will use default values.</p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"### 🎯 **Quick Start: Download Sample CSV Template**\")\n",
        "\n",
        "    sample_data = create_sample_csv_data(selected_features, label_encoders, feature_modes)\n",
        "    sample_csv = pd.DataFrame(sample_data).to_csv(index=False)\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.download_button(\n",
        "            label=\"📥 Download Sample CSV Template\",\n",
        "            data=sample_csv,\n",
        "            file_name=\"gene_mutation_template.csv\",\n",
        "            mime=\"text/csv\",\n",
        "            help=\"Download this template and fill it with your mutation data\"\n",
        "        )\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"👀 Preview Sample Data\"):\n",
        "            st.dataframe(pd.DataFrame(sample_data), use_container_width=True)\n",
        "\n",
        "    st.markdown(\"### 📊 **Model Features by Category**\")\n",
        "\n",
        "    categories = {\n",
        "        \"🧬 Basic Mutation Info\": [f for f in selected_features if any(x in f.lower() for x in ['mutation', 'allele', 'type', 'cpg'])],\n",
        "        \"📍 Genomic Position\": [f for f in selected_features if any(x in f.lower() for x in ['hg', 'start', 'end', 'cdna', 'exon'])],\n",
        "        \"🔬 Protein Effects\": [f for f in selected_features if 'protein' in f.lower()],\n",
        "        \"📊 Prediction Scores\": [f for f in selected_features if any(x in f.lower() for x in ['sift', 'polyphen', 'provean', 'condel', 'mutassessor'])],\n",
        "        \"🏥 Clinical Data\": [f for f in selected_features if any(x in f.lower() for x in ['disease', 'tumor', 'cancer', 'pathology', 'smoking'])],\n",
        "    }\n",
        "\n",
        "    for category, features in categories.items():\n",
        "        if features:\n",
        "            with st.expander(f\"{category} ({len(features)} features)\"):\n",
        "                for i, feature in enumerate(sorted(features), 1):\n",
        "                    st.write(f\"{i}. `{feature}`\")\n",
        "\n",
        "    st.markdown(\"### 💡 **Tips for Best Results**\")\n",
        "    st.markdown(\"\"\"\n",
        "    - **Include as many relevant columns as possible** for better predictions\n",
        "    - **Use consistent column names** matching the features above\n",
        "    - **Handle missing values**: Use 'Unknown' or leave blank for categorical data\n",
        "    - **Ensure numeric columns** contain numbers, not text\n",
        "    - **Avoid special characters** in categorical values\n",
        "    \"\"\")\n",
        "\n",
        "def create_sample_csv_data(selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Create sample CSV data for download\"\"\"\n",
        "    num_samples = 3\n",
        "    sample_data = {}\n",
        "    log_transformed_columns = ['Leukemia_Lymhoma_Freq', 'Solid_Tumor_Freq', 'Tumor_Freq', 'Cell_line_Freq']\n",
        "\n",
        "    for feature in selected_features:\n",
        "        if feature in label_encoders:\n",
        "            classes = list(label_encoders[feature].classes_)\n",
        "            sample_data[feature] = np.random.choice(classes, size=num_samples)\n",
        "        else:\n",
        "            mode_value = feature_modes.get(feature, 0)\n",
        "            if isinstance(mode_value, (int, float)):\n",
        "                values = np.random.uniform(low=max(0, mode_value - 1), high=mode_value + 1, size=num_samples)\n",
        "                if feature in log_transformed_columns:\n",
        "                    values = np.log1p(values)\n",
        "                sample_data[feature] = values\n",
        "            else:\n",
        "                sample_data[feature] = [mode_value] * num_samples\n",
        "\n",
        "    return sample_data\n",
        "\n",
        "def preprocess_input(user_input, selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Preprocess user input to match model expectations\"\"\"\n",
        "    processed_input = {}\n",
        "    log_transformed_columns = ['Leukemia_Lymhoma_Freq', 'Solid_Tumor_Freq', 'Tumor_Freq', 'Cell_line_Freq']\n",
        "\n",
        "    for feature in selected_features:\n",
        "        if feature in user_input:\n",
        "            value = user_input[feature]\n",
        "\n",
        "            if feature in label_encoders:\n",
        "                try:\n",
        "                    if isinstance(value, str):\n",
        "                        processed_input[feature] = label_encoders[feature].transform([value])[0]\n",
        "                    else:\n",
        "                        processed_input[feature] = value\n",
        "                except Exception:\n",
        "                    processed_input[feature] = label_encoders[feature].transform([label_encoders[feature].classes_[0]])[0]\n",
        "                    st.warning(f\"Invalid value for {feature}: {value}. Using default encoded value.\")\n",
        "            else:\n",
        "                if feature in log_transformed_columns and isinstance(value, (int, float)):\n",
        "                    processed_input[feature] = np.log1p(value)\n",
        "                else:\n",
        "                    processed_input[feature] = value\n",
        "        else:\n",
        "            default_value = feature_modes.get(feature, 0.0)\n",
        "            if feature in log_transformed_columns and isinstance(default_value, (int, float)):\n",
        "                processed_input[feature] = np.log1p(default_value)\n",
        "            else:\n",
        "                processed_input[feature] = default_value\n",
        "\n",
        "    return processed_input\n",
        "\n",
        "def make_prediction(user_input, model, selected_features, label_encoders, feature_modes):\n",
        "    \"\"\"Make a single prediction using XGBoost\"\"\"\n",
        "    try:\n",
        "        processed_input = preprocess_input(user_input, selected_features, label_encoders, feature_modes)\n",
        "\n",
        "        input_df = pd.DataFrame([processed_input])\n",
        "        input_df = input_df[selected_features]\n",
        "\n",
        "        # Ensure correct data types and convert feature names to list\n",
        "        for col in input_df.columns:\n",
        "            if col in label_encoders:\n",
        "                input_df[col] = input_df[col].astype(int)\n",
        "            else:\n",
        "                input_df[col] = pd.to_numeric(input_df[col], errors='coerce').fillna(0)\n",
        "\n",
        "        # Convert to DMatrix with proper feature names\n",
        "        feature_names = list(input_df.columns)  # Convert Index to list of strings\n",
        "        dmatrix = xgb.DMatrix(input_df.values, feature_names=feature_names)\n",
        "\n",
        "        prediction_proba = model.predict(dmatrix)[0]\n",
        "        prediction = 'Pathogenic' if prediction_proba >= 0.5 else 'Benign'\n",
        "\n",
        "        confidence = prediction_proba if prediction == 'Pathogenic' else 1 - prediction_proba\n",
        "\n",
        "        return prediction, confidence\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error making prediction: {str(e)}\")\n",
        "        st.error(\"Please check input data format and try again.\")\n",
        "        return None, 0.0\n",
        "\n",
        "def make_batch_predictions(df, model, selected_features, label_encoders, feature_modes, batch_size=500):\n",
        "    \"\"\"Make batch predictions using XGBoost\"\"\"\n",
        "    errors = []\n",
        "    try:\n",
        "        input_df = df.copy()\n",
        "        log_transformed_columns = ['Leukemia_Lymhoma_Freq', 'Solid_Tumor_Freq', 'Tumor_Freq', 'Cell_line_Freq']\n",
        "\n",
        "        # Ensure all required features are present\n",
        "        for feature in selected_features:\n",
        "            if feature not in input_df.columns:\n",
        "                input_df[feature] = feature_modes.get(feature, 0)\n",
        "\n",
        "        # Process features\n",
        "        for feature in selected_features:\n",
        "            if feature in input_df.columns:\n",
        "                if feature in label_encoders:\n",
        "                    try:\n",
        "                        input_df[feature] = input_df[feature].fillna('Unknown').astype(str)\n",
        "                        encoder_classes = [str(c) for c in label_encoders[feature].classes_]\n",
        "                        def safe_transform(value):\n",
        "                            value = str(value).strip()\n",
        "                            return label_encoders[feature].transform([value])[0] if value in encoder_classes else label_encoders[feature].transform([encoder_classes[0]])[0]\n",
        "                        input_df[feature] = input_df[feature].apply(safe_transform).astype(int)\n",
        "                    except Exception as enc_error:\n",
        "                        errors.append(f\"Error encoding feature {feature}: {str(enc_error)}\")\n",
        "                        input_df[feature] = feature_modes.get(feature, 0)\n",
        "                elif feature in log_transformed_columns:\n",
        "                    input_df[feature] = pd.to_numeric(input_df[feature], errors='coerce').abs().fillna(0)\n",
        "                    input_df[feature] = np.log1p(input_df[feature])\n",
        "                else:\n",
        "                    input_df[feature] = pd.to_numeric(input_df[feature], errors='coerce').fillna(0)\n",
        "\n",
        "        all_predictions = []\n",
        "        all_probabilities = []\n",
        "        progress_bar = st.progress(0)\n",
        "        total_batches = (len(input_df) + batch_size - 1) // batch_size\n",
        "\n",
        "        for i in range(0, len(input_df), batch_size):\n",
        "            batch_df = input_df.iloc[i:i+batch_size][selected_features]\n",
        "            batch_df = batch_df.fillna(0)\n",
        "\n",
        "            # Convert to DMatrix with proper feature names\n",
        "            feature_names = list(batch_df.columns)  # Convert Index to list of strings\n",
        "            dmatrix = xgb.DMatrix(batch_df.values, feature_names=feature_names)\n",
        "\n",
        "            probabilities = model.predict(dmatrix)\n",
        "            predictions = ['Pathogenic' if p >= 0.5 else 'Benign' for p in probabilities]\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_probabilities.extend(probabilities)\n",
        "\n",
        "            progress_bar.progress(min((i + batch_size) / len(input_df), 1.0))\n",
        "\n",
        "        progress_bar.empty()\n",
        "\n",
        "        if errors:\n",
        "            with open('prediction_errors.txt', 'w') as f:\n",
        "                f.write(\"\\n\".join(errors))\n",
        "            st.markdown(\"### Download Error Log\")\n",
        "            st.download_button(\n",
        "                label=\"📋 Download Error Log\",\n",
        "                data=open('prediction_errors.txt', 'rb'),\n",
        "                file_name=\"prediction_errors.txt\",\n",
        "                mime=\"text/plain\",\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "        return all_predictions, all_probabilities\n",
        "\n",
        "    except Exception as e:\n",
        "        errors.append(str(e))\n",
        "        with open('prediction_errors.txt', 'w') as f:\n",
        "            f.write(\"\\n\".join(errors))\n",
        "        st.error(f\"Error in batch predictions: {str(e)}\")\n",
        "        st.error(\"Check your CSV for valid data (correct columns, data types).\")\n",
        "        st.download_button(\n",
        "            label=\"📋 Download Error Log\",\n",
        "            data=open('prediction_errors.txt', 'rb'),\n",
        "            file_name=\"prediction_errors.txt\",\n",
        "            mime=\"text/plain\"\n",
        "        )\n",
        "        return [], []\n",
        "\n",
        "def display_prediction_result(prediction, probability):\n",
        "    \"\"\"Display prediction result with enhanced styling\"\"\"\n",
        "    if prediction is None:\n",
        "        st.error(\"Prediction failed. Please check your input data.\")\n",
        "        return\n",
        "\n",
        "    if prediction == \"Pathogenic\":\n",
        "        st.markdown(f'''\n",
        "        <div class=\"prediction-result pathogenic\">\n",
        "            <strong>⚠️ PATHOGENIC</strong><br>\n",
        "            XGBoost Confidence: {probability:.2%}\n",
        "        </div>\n",
        "        ''', unsafe_allow_html=True)\n",
        "\n",
        "        st.warning(\"\"\"\n",
        "        **Clinical Interpretation:**\n",
        "        ⚠️ This mutation is predicted to be **PATHOGENIC** with high confidence.\n",
        "        🔍 Consider further clinical evaluation and functional studies.\n",
        "        📌 May have significant impact on protein function.\n",
        "        \"\"\")\n",
        "\n",
        "    elif prediction == \"Benign\":\n",
        "        st.markdown(f'''\n",
        "        <div class=\"prediction-result benign\">\n",
        "            <strong>✔️ BENIGN</strong><br>\n",
        "            XGBoost Confidence: {probability:.2%}\n",
        "        </div>\n",
        "        ''', unsafe_allow_html=True)\n",
        "\n",
        "        st.success(\"\"\"\n",
        "        **Clinical Interpretation:**\n",
        "        ✔️ This mutation is predicted to be **BENIGN** with high confidence.\n",
        "        🧬 Likely represents a neutral polymorphism.\n",
        "        📌 Low likelihood of clinical significance.\n",
        "        \"\"\")\n",
        "\n",
        "# Main application\n",
        "def main():\n",
        "    st.markdown('<h1 class=\"main-header\">🧬 XGBoost Gene Mutation Pathogenicity Predictor</h1>', unsafe_allow_html=True)\n",
        "\n",
        "    # Load model artifacts\n",
        "    model, selected_features, label_encoders, feature_modes = load_model_artifacts()\n",
        "\n",
        "    if model is None:\n",
        "        st.stop()\n",
        "\n",
        "    st.markdown(\"### 🎯 Predict whether a gene mutation is **Pathogenic** or **Benign** using XGBoost AI\")\n",
        "\n",
        "    # Model info\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        st.markdown('<div class=\"metric-card\"><h4>🤖 Model</h4><p>XGBoost Classifier</p></div>', unsafe_allow_html=True)\n",
        "    with col2:\n",
        "        st.markdown(f'<div class=\"metric-card\"><h4>📊 Features</h4><p>{len(selected_features)} Variables</p></div>', unsafe_allow_html=True)\n",
        "    with col3:\n",
        "        st.markdown('<div class=\"metric-card\"><h4>🎯 Accuracy</h4><p>99.99%</p></div>', unsafe_allow_html=True)\n",
        "\n",
        "    # Add prominent CSV upload section at the top\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"upload-section\">\n",
        "        <h3>📁 Quick CSV Upload for Batch Predictions</h3>\n",
        "        <p>Upload your gene mutation CSV file to get instant XGBoost pathogenicity predictions for multiple mutations!</p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # CSV Upload section\n",
        "    with st.expander(\"🚀 **UPLOAD CSV FILE FOR BATCH PREDICTIONS**\", expanded=True):\n",
        "        csv_upload_section(model, selected_features, label_encoders, feature_modes)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # Sidebar for navigation\n",
        "    st.sidebar.title(\"🧭 Navigation\")\n",
        "    st.sidebar.markdown(\"**XGBoost Gene Mutation Predictor**\")\n",
        "    page = st.sidebar.selectbox(\"Choose a page:\", [\n",
        "        \"Single Prediction\",\n",
        "        \"Advanced Batch Upload\",\n",
        "        \"Feature Information\",\n",
        "        \"CSV Format Guide\",\n",
        "        \"Model Performance\"\n",
        "    ])\n",
        "\n",
        "    if page == \"Single Prediction\":\n",
        "        single_prediction_page(model, selected_features, label_encoders, feature_modes)\n",
        "    elif page == \"Advanced Batch Upload\":\n",
        "        batch_prediction_page(model, selected_features, label_encoders, feature_modes)\n",
        "    elif page == \"CSV Format Guide\":\n",
        "        csv_format_guide_page(selected_features, label_encoders, feature_modes)\n",
        "    elif page == \"Model Performance\":\n",
        "        model_performance_page()\n",
        "    else:\n",
        "        feature_information_page(selected_features)\n",
        "\n",
        "def batch_prediction_page(model, selected_features, label_encoders, feature_modes):\n",
        "    st.markdown('<h2 class=\"sub-header\">Advanced Batch Mutation Prediction</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"Upload a CSV file with mutation data for batch prediction with advanced options.\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        try:\n",
        "            df = pd.read_csv(uploaded_file)\n",
        "            st.success(f\"File uploaded successfully! Shape: {df.shape}\")\n",
        "\n",
        "            st.markdown(\"**Preview of uploaded data:**\")\n",
        "            st.dataframe(df.head())\n",
        "\n",
        "            batch_size = st.slider(\"Batch Size for Processing\", min_value=100, max_value=1000, value=500, step=100)\n",
        "\n",
        "            if st.button(\"🚀 Run Batch Prediction\", type=\"primary\"):\n",
        "                predictions, probabilities = make_batch_predictions(\n",
        "                    df, model, selected_features, label_encoders, feature_modes, batch_size\n",
        "                )\n",
        "\n",
        "                results_df = df.copy()\n",
        "                results_df['Predicted_Pathogenicity'] = predictions\n",
        "                results_df['Pathogenic_Probability'] = [f\"{p:.4f}\" for p in probabilities]\n",
        "\n",
        "                st.markdown(\"**Prediction Results:**\")\n",
        "                st.dataframe(results_df, use_container_width=True)\n",
        "\n",
        "                csv = results_df.to_csv(index=False)\n",
        "                st.download_button(\n",
        "                    label=\"📥 Download Results as CSV\",\n",
        "                    data=csv,\n",
        "                    file_name=\"mutation_predictions.csv\",\n",
        "                    mime=\"text/csv\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "                st.markdown(\"**Prediction Summary:**\")\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "                with col1:\n",
        "                    st.metric(\"Total Predictions\", len(predictions))\n",
        "                with col2:\n",
        "                    st.metric(\"Pathogenic\", sum(1 for p in predictions if p == 'Pathogenic'))\n",
        "                with col3:\n",
        "                    st.metric(\"Benign\", sum(1 for p in predictions if p == 'Benign'))\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error processing file: {e}\")\n",
        "            st.info(\"Please check that your CSV file contains valid data and correct column names.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7dPzZPpLttu",
        "outputId": "3d93c850-8669-4307-c0cf-65489d9fa761"
      },
      "id": "E7dPzZPpLttu",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing xgboost_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n",
        "!streamlit run xgboost_app.py & sleep 5 && npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwiRmN4lURIy",
        "outputId": "377e50a8-83ff-42cf-c843-aab194d3deb6"
      },
      "id": "cwiRmN4lURIy",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.27.215.14\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.27.215.14:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0Kyour url is: https://deep-plants-itch.loca.lt\n",
            "2025-06-01 15:52:21.888 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/elements/lib/\u001b[0m\u001b[1mimage_utils.py\u001b[0m:286 in \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m image_to_url                                                                         \u001b[31m \u001b[0m\n",
            "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'feature_importance.png'\u001b[0m\n",
            "\n",
            "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
            "\n",
            "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/\u001b[0m\u001b[1mmemory_media_file_storage.\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1mpy\u001b[0m:163 in _read_file                                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'feature_importance.png'\u001b[0m\n",
            "\n",
            "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m 121 in exec_func_with_error_handling                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1m.py\u001b[0m:645 in code_to_exec                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/content/\u001b[0m\u001b[1mxgboost_app.py\u001b[0m:1007 in <module>                                             \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m1004 \u001b[0m\u001b[2m│   │   │   \u001b[0mst.info(\u001b[33m\"\u001b[0m\u001b[33mPlease check that your CSV file contains valid data and \u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m1005 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m1006 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                                    \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1007 \u001b[2m│   \u001b[0m\u001b[1;4mmain()\u001b[0m                                                                    \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m1008 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/content/\u001b[0m\u001b[1mxgboost_app.py\u001b[0m:951 in main                                                  \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 948 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m page == \u001b[33m\"\u001b[0m\u001b[33mCSV Format Guide\u001b[0m\u001b[33m\"\u001b[0m:                                          \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 949 \u001b[0m\u001b[2m│   │   \u001b[0mcsv_format_guide_page(selected_features, label_encoders, feature_mode \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 950 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m page == \u001b[33m\"\u001b[0m\u001b[33mModel Performance\u001b[0m\u001b[33m\"\u001b[0m:                                         \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 951 \u001b[2m│   │   \u001b[0m\u001b[1;4mmodel_performance_page()\u001b[0m                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 952 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 953 \u001b[0m\u001b[2m│   │   \u001b[0mfeature_information_page(selected_features)                           \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 954 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/content/\u001b[0m\u001b[1mxgboost_app.py\u001b[0m:591 in model_performance_page                                \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 588 \u001b[0m\u001b[2m│   │   \u001b[0mst.markdown(\u001b[33m'\u001b[0m\u001b[33m<div class=\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mmetric-card confidence-high\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m><h4>🎯 Recall</\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 589 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 590 \u001b[0m\u001b[2m│   \u001b[0mst.markdown(\u001b[33m\"\u001b[0m\u001b[33m### 📈 Feature Importance\u001b[0m\u001b[33m\"\u001b[0m)                                  \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 591 \u001b[2m│   \u001b[0m\u001b[1;4mst.image(\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mfeature_importance.png\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m, use_column_width=\u001b[0m\u001b[1;4;94mTrue\u001b[0m\u001b[1;4m)\u001b[0m                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 592 \u001b[0m\u001b[2m│   \u001b[0mst.markdown(\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 593 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m*Top 20 most important features for pathogenicity prediction*\u001b[0m             \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 594 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m)                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/\u001b[0m\u001b[1mmetrics_util.py\u001b[0m:444 in     \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m wrapped_func                                                                         \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/elements/\u001b[0m\u001b[1mimage.py\u001b[0m:181 in image     \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/elements/lib/\u001b[0m\u001b[1mimage_utils.py\u001b[0m:442 in \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m marshall_images                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/elements/lib/\u001b[0m\u001b[1mimage_utils.py\u001b[0m:298 in \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m image_to_url                                                                         \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/\u001b[0m\u001b[1mmedia_file_manager.py\u001b[0m:226  \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m in add                                                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/\u001b[0m\u001b[1mmemory_media_file_storage.\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1mpy\u001b[0m:114 in load_and_get_id                                                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/\u001b[0m\u001b[1mmemory_media_file_storage.\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1mpy\u001b[0m:166 in _read_file                                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[1;91mMediaFileStorageError: \u001b[0mError opening \u001b[32m'feature_importance.png'\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}